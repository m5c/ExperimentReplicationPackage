{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RESTify Experiment Replication Package","text":"<p>All you need to replicate our findings, in one place.</p> <p>tl;dr: We offer  a pre-rendered Jupyter Notebook. (No installation required) If you want to actually replicate, try the docker for minimal effort. (Takes about 2 minutes of your time)</p>"},{"location":"#about","title":"About","text":"<p>As part of our submission to the MODELS 2024 conference, we offer a replication package that allows fast and independent replication of all our results and interpretations. This page serves as starting point for the various components needed.</p>"},{"location":"#package-content","title":"Package Content","text":"<p>This section hot-links package content by scope</p>"},{"location":"#replication","title":"Replication","text":"<ul> <li>Result Replication: Center-piece of our replication package. <ul> <li>You can recreate all paper figures and numbers using an interactive notebook.</li> <li>We provide the raw data. You crunch it yourself, using our provided statistical scripts.</li> <li>You can inspect a pre-rendered notebook or run a one liner-docker command for local replication.</li> </ul> </li> </ul>"},{"location":"#material","title":"Material","text":"<ul> <li>Recruitment Material: A reference to the webpage used for participant recruitment.</li> <li>Group Allocation Algo: Source code and documentation of the algorithm implemented to create a balanced group allocation.</li> <li>Task Instruction Material: Collection with instructions for the task instructions. There are four, since the experiment had four groups with diverging task context and order.</li> <li>Sample Legacy Applications (Objects): The sample applications used task for training or actual conversion task.</li> </ul>"},{"location":"#collected-data","title":"Collected Data","text":"<ul> <li>Raw Experiment Collected Data: Raw data collected throughout the experiment.</li> <li>Submission Correctness Evaluation Tool: Sources and documentation of the analyzer tool that we implemented to assess correctness of participant submissions. </li> <li>Extracted Times and Video Observations.md: CSV and textual summary files that conclude data extracted from video material viewing, such as transcript of observations and time measurements for the individual conversion tasks.</li> </ul>"},{"location":"about/","title":"About","text":"<p>This is the replication package of the RESTify controlled Experiment.</p> <ul> <li>PI: Maximilian Schiedermeier</li> <li>Academic Supervisors: Bettina Kemme, J\u00f6rg Kienzle</li> </ul>"},{"location":"allocation/","title":"Group Allocation","text":""},{"location":"allocation/#source-code","title":"Source Code","text":"<p>The source code of the MiniMax implementation and documentation is available on GitHub.</p>"},{"location":"allocation/#explanations","title":"Explanations","text":"<p>We implemented a custom MiniMax Heuristic, to assess the participant's skill profiles and create balanced experiment groups.  </p> <ul> <li>To maintain transparency we provide source code and documentation of the heuristic used to create the participant allocations.</li> <li>The program parses all provided self assessment forms (see corresponding entry of replication bundle which they provided during recruitment, and then performs a MiniMax search for the fairest group allocation.</li> <li>A side product of this software is the generation of personalized emails for following communication with the individual participants. </li> </ul> <p>Since the purpose of this program is to select of all applicants and provide a mapping from their legal names to pseudonyms, it can be only executed with access to the participant details. The latter we cannot release for legal reasons.</p>"},{"location":"analyzer/","title":"Submission Analyzer","text":"<p>We wrote an open source tool to test migrated applications: Analyzer Sources and Documentation on GitHub</p>"},{"location":"analyzer/#how-it-works","title":"How it works","text":"<ul> <li>You download the raw participant submission data from this webpage</li> <li>You clone the analyzer and run it. It produces a CSV test report.</li> <li>You compare the test report against the one we use for our own statistical analysis, so you see out statistical analysis actually operates on the real data.</li> </ul>"},{"location":"data/","title":"Data. Like... all of it. Kind of.","text":"<p>All data we collected. </p> <p>In some cases we had to anonymize, to protect participant identity. But you can still replicate all results. Cheers.</p>"},{"location":"data/#video-observations","title":"Video Observations","text":"<p>We collected more than 72 hours of video onscreen recordings throughout the experiment. Participants were asked to avoid capturing personal information or identifiers. Unfortunately this request was widely ignored. To preserve participant anonymity, we cannot provide the original video material. Bummer. We can however provide all information, extracted from the video material.</p> <ul> <li>Task solving and task preparation times: We measured how much time every participant spent on the actual project conversion tasks and the instructions and provide precise information on their time spendings.</li> <li>Task deviations, difficulties, remarkable observations: We provide for each participant and each refactoring task a transcript of all noteworthy events. This includes problems with specific task phases, problems with software used, even information on their task solving activity itself.</li> <li>Participant methodology feedback preferences</li> </ul> <p>Here's the actual data, in various file formats:</p> <ul> <li>Mac Numbers File</li> <li>Microsoft Excel File</li> <li>CSV File</li> </ul>"},{"location":"data/#participant-feedback","title":"Participant Feedback","text":"<p>Participant issued comments on the study, issues, preferences after study conclusion.</p> <p>We crunched it all for you, in various file formats:</p> <ul> <li>Mac Numbers File</li> <li>Microsoft Excel File</li> <li>CSV File </li> </ul> <p>We also created an informal meta summary of most common issues observed in task solving.</p>"},{"location":"data/#code-model-submissions","title":"Code / Model Submissions","text":"<p>Everything the participants actively produced on their endevour to migrate the provided legacy applications:</p> <ul> <li>All raw code and all models (anonymized) (and the corresponding generated code), provided by participants.</li> <li>All patched code and all models (anonymized) (and the corresponding generated code), provided by participants.</li> </ul> <p>We patched some submissions before testing, i.e. in some cases a minimal configuration mistake prevented testing. See our publication for the details on the patches performed.</p>"},{"location":"data/#participant-test-results","title":"Participant Test Results","text":"<p>We tested all submissions against the requested REST API interface description.</p> <p>Here's a CSV with all the results. You can reproduce the CSV using the above code / model submissions and our provided tester.</p>"},{"location":"material/","title":"Training and Task Material","text":"<p>The original task training and task instructions material. One for each of the four experiment groups:</p> <ul> <li>Red Group</li> <li>Green Group</li> <li>Blue Group</li> <li>Yellow Group</li> </ul> <p>Task context and order changes, depending on which group a participant was allocated to.</p>"},{"location":"objects/","title":"Objects","text":"<p>The study contains three sample  lecagy applications for migration to REST.</p>"},{"location":"objects/#the-zoo","title":"The Zoo","text":"<p>The zoo is only used for subject training. It is smaller than the applications used for the migration tasks. Zoo Legacy Sources on GitHub</p>"},{"location":"objects/#the-bookstore","title":"The BookStore","text":"<p>Legacy application No.1: A simple e-commerce application. BookStore Legacy Sources on GitHub</p>"},{"location":"objects/#xox","title":"Xox","text":"<p>Legacy application No.2: A simple turn based board game classic. Xox Legacy Sources on GitHub</p>"},{"location":"recruitment/","title":"Recruitment Webpage","text":"<p>Here you find anonymized references to the material used for recruitment:</p> <ul> <li>Original Recruitment webpage</li> <li>The auto assessment form used to assess preliminary participant skills</li> </ul>"},{"location":"replication/","title":"Result Replication","text":"<p>All statistical figures and listings in our paper submission were created programmatically. The code to produce them is publicly available and well documented.</p> <p>On the dedicated project page, we provide:</p> <ul> <li>The raw data (but you get that also here, for your convenience ;) )</li> <li>The code used for statistical analysis</li> <li>Instructions on how to very rapidly replicate / reproduce our results</li> </ul> <p>Spoiler alert: we use docker + jupyter, so you don't need to install anything.</p>"},{"location":"replication/#where-to-start","title":"Where to Start","text":"<p>We provide several access points, for fast to thorough replication:</p> <ul> <li>Static, rendered Jupyter Notebook: You can inspect a static one-shot render of our Notebook on GitHub. You only need a browser. Please note that the anonymization process damaged some of the integrated figures. We apologize for the inconvenience.</li> <li>Dynamic, using a docker configuration. See install instructions for Docker.</li> <li>Dynamic, your own Jupyter Notebook. See install instructions for native Jupyter</li> <li>Dynamic, using the raw python sources, and an IDE. See install instructions for PyCharm</li> </ul>"}]}